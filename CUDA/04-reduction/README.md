# CUDA. Reduction

Код с примерами использования Reduction:
1. [Пример 0. Использование агрегации между блоками](/CUDA/04-reduction/00-stupid-sum)
2. [Пример 1. Реализация при помощи Shared Memory](/CUDA/04-reduction/01-default-sum)
3. [Пример 2. Меняем процесс математики](/CUDA/04-reduction/02-another-math)
4. [Пример 3. Затрагиваем вопрос Bank Conflict](/CUDA/04-reduction/03-improving-bank-conflicts)
5. [Пример 4. Первая операция перед загрузкой в Shared Memory](/CUDA/04-reduction/04-add-on-load)
6. [Пример 5. Операции внутри Warp-а](/CUDA/04-reduction/05-warp-reduce)
7. [Пример 6. Ассемблерные инструкции внутри Warp-а](/CUDA/04-reduction/06-warp-design-specific)

## Постановка задачи

В предыдущих блоках мы производили операции между массивами (сложение, перемножение). Однако, классическую задачу паралелльных вычислений, вычисление суммы элементов, мы не рассматривали. 

Рассмотрим решение суммы чисел массива. Такие задачи называются задачами Reduce, поскольку выполняют операцию агрегирования значений. 

**Важно:** Задача может быть решена для любой операции, которая удовлетворяет следующим условиям:
1. Ассоциативности (`a + (b + c) = (a + b) + c`)
2. Коммутативности (`a + b = b + a`)
3. Наличие "нейтрального" элемента: (`a + 0 = 0 + a = a`).

## Решение 0. Наивное решение

https://github.com/akhtyamovpavel/ParallelComputationExamples/blob/9867180abf08ea32bfb868fa292edfcf399d5060/CUDA/04-reduction/00-stupid-sum/main.cu#L5-L12

Мы разбиваем массив на блоки размером 1024. После этого каждый поток вычисляет суммы своего "блока" и получает результат.

https://github.com/akhtyamovpavel/ParallelComputationExamples/blob/9867180abf08ea32bfb868fa292edfcf399d5060/CUDA/04-reduction/00-stupid-sum/main.cu#L50-L52

После выполнения ядра код вычисляет сумму элементов в своём блоке.

В примере `StupidAdd` мы видели, что из-за проблем когерентности кэша такой способ вычисления является неэффективным, поэтому код работает очень медленно.

В итоге, сумма $2^{20}$ элементов массива вычисляется за 15 ms.

## Решение 0.5. Необходима ручная настройка

Поменяем формат взаимодействия элементов. Предположим, что в распоряжении имеется 1024 вычислительных ядра. 
Каждый элемент должен сохранять когерентность кэшей, поэтому поток с номером 0 должен вычислять сумму элементов $(0, 1024, 2048, ...)$, поток 1 - $(1, 1025, 2049, ...)$.

Таким образом, все потоки внутри одного warp-а будут брать один элемент из L1/L2-кэша:

https://github.com/akhtyamovpavel/ParallelComputationExamples/blob/9867180abf08ea32bfb868fa292edfcf399d5060/CUDA/04-reduction/00-stupid-sum/normal_sum.cu#L18-L23

Код запускается на количестве потоков, равное количеству Streaming Multiprocessor-ов: 

https://github.com/akhtyamovpavel/ParallelComputationExamples/blob/9867180abf08ea32bfb868fa292edfcf399d5060/CUDA/04-reduction/00-stupid-sum/normal_sum.cu#L67

В результате запуска кода получаем время работы, равное 10 ms. 
